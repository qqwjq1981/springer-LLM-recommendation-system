{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## News Recommendation by Combining Embedding with Learning to Rank Models\n",
        "#### Objective\n",
        "\n",
        "- Learn how to retrieve candidate articles for each user using embedding-based semantic similarity.\n",
        "- Apply both baseline similarity ranking and advanced learning-to-rank models (e.g., LambdaMART) to sort the retrieved candidates.\n",
        "- Evaluate recommendation quality using standard metrics such as Precision@k, Recall@k, and NDCG@k.\n",
        "\n",
        "#### Prerequisites\n",
        "- Get model API keys from yaml file."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install tiktoken\n",
        "# %pip install -U langchain-community\n",
        "# %pip install weaviate-client\n",
        "# %pip install lightgbm"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1742301523780
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import openai\n",
        "import time\n",
        "\n",
        "import logging\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Read the YAML file\n",
        "with open('./../../../Curify/curify_api.yaml', 'r') as yaml_file:\n",
        "    data = yaml.safe_load(yaml_file)\n",
        "\n",
        "openai_api_key = data.get('openai').get('api_key')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key= openai_api_key\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1742301524074
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Data Preparation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load data\n",
        "file_path = './../Data/news-recommendation/'\n",
        "user_df = pd.read_csv(file_path + \"user_profiles.tsv\", sep='\\t').head(10)\n",
        "item_df = pd.read_csv(file_path + \"news_summary.tsv\", sep='\\t').drop_duplicates()"
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1742301524342
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Retrieval Set Generation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def compute_retrieval_set(user_embeddings, article_embeddings, k=10):\n",
        "    \"\"\"\n",
        "    Use Nearest Neighbors to find top-k articles for each user based on cosine similarity.\n",
        "\n",
        "    Args:\n",
        "        user_embeddings (pd.DataFrame): DataFrame with user_id as index and embedding columns.\n",
        "        article_embeddings (pd.DataFrame): DataFrame with item_id as index and embedding columns.\n",
        "        k (int): Number of nearest neighbors to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping of user_id to a list of top-k item_ids.\n",
        "    \"\"\"\n",
        "    k = min(k, len(article_embeddings))\n",
        "\n",
        "    # Fit Nearest Neighbors model on article embeddings\n",
        "    nn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
        "    nn.fit(article_embeddings.values)\n",
        "\n",
        "    # Perform kNN search for each user\n",
        "    distances, indices = nn.kneighbors(user_embeddings.values)\n",
        "\n",
        "    # Retrieve corresponding item_ids from index\n",
        "    item_ids = article_embeddings.index.to_list()\n",
        "    user_ids = user_embeddings.index.to_list()\n",
        "\n",
        "    user_to_items = {\n",
        "        user_id: [item_ids[idx] for idx in top_k_idxs]\n",
        "        for user_id, top_k_idxs in zip(user_ids, indices)\n",
        "    }\n",
        "\n",
        "    return user_to_items"
      ],
      "outputs": [],
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1742301524455
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: User-Item Relevance Labeling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_label_user_interest(users, articles, user_to_article_map, model=\"gpt-4o-mini\", batch_size=10):\n",
        "    \"\"\"\n",
        "    Labels user interest in news articles based on LinkedIn profiles using OpenAI API.\n",
        "    Output is 1 for Interested, 0 for Not Interested (one line per user-article pair).\n",
        "\n",
        "    Args:\n",
        "        users (dict): User profiles, {user_id: profile text}.\n",
        "        articles (dict): News articles, {item_id: article summary}.\n",
        "        user_to_article_map (dict): {user_id: [item_id1, item_id2, ...]}.\n",
        "        model (str): OpenAI model to use.\n",
        "        batch_size (int): Number of user-article pairs per prompt.\n",
        "\n",
        "    Returns:\n",
        "        dict: {user_id: {item_id: interest_label (0 or 1)}}\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    all_pairs = [(user_id, item_id) for user_id, item_ids in user_to_article_map.items() for item_id in item_ids]\n",
        "\n",
        "    for i in range(0, len(all_pairs), batch_size):\n",
        "        batch = all_pairs[i:i + batch_size]\n",
        "\n",
        "        # Build prompt\n",
        "        prompt = (\n",
        "            \"For each of the following user and article pairs, determine interest level.\\n\"\n",
        "            \"Respond only with a single line per pair, format:\\n\"\n",
        "            \"`user_id, item_id, 1` for Interested OR `user_id, item_id, 0` for Not Interested.\\n\"\n",
        "            \"Do NOT add extra explanations or formatting.\\n\\n\"\n",
        "        )\n",
        "\n",
        "        for user_id, item_id in batch:\n",
        "            prompt += f\"User ID: {user_id}\\nProfile: {users[user_id]}\\n\"\n",
        "            prompt += f\"Article ID: {item_id}\\nArticle: {articles[item_id]}\\n\\n\"\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.3\n",
        "            )\n",
        "\n",
        "            output = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Parse each line of output\n",
        "            for line in output.splitlines():\n",
        "                parts = line.strip().split(\",\")\n",
        "                if len(parts) != 3:\n",
        "                    print(f\"⚠️ Skipping malformed line: {line}\")\n",
        "                    continue\n",
        "                uid, iid, label = parts[0].strip(), parts[1].strip(), parts[2].strip()\n",
        "                try:\n",
        "                    label = int(label)\n",
        "                    if uid not in results:\n",
        "                        results[uid] = {}\n",
        "                    results[uid][iid] = label\n",
        "                except ValueError:\n",
        "                    print(f\"⚠️ Invalid label in line: {line}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error calling OpenAI API: {str(e)}\")\n",
        "\n",
        "    return results"
      ],
      "outputs": [],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1742301525154
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Recommendation Approaches\n",
        "\n",
        "**Direct Embedding Similarity**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def recommend_top_k_items(user_embeddings_df, item_embeddings_df, top_k=5):\n",
        "    \"\"\"\n",
        "    Recommend top-k items to each user based on cosine similarity between user and item embeddings.\n",
        "\n",
        "    Args:\n",
        "        user_embeddings_df (pd.DataFrame): DataFrame with user embeddings, indexed by 'user_id'.\n",
        "        item_embeddings_df (pd.DataFrame): DataFrame with item embeddings, indexed by 'item_id'.\n",
        "        top_k (int): Number of items to recommend per user.\n",
        "\n",
        "    Returns:\n",
        "        dict: {user_id: [item_id1, item_id2, ...]} of top-k recommended items.\n",
        "    \"\"\"\n",
        "    user_ids = user_embeddings_df.index.tolist()\n",
        "    item_ids = item_embeddings_df.index.tolist()\n",
        "\n",
        "    # Compute cosine similarity matrix: shape (num_users, num_items)\n",
        "    similarity_matrix = cosine_similarity(user_embeddings_df.values, item_embeddings_df.values)\n",
        "\n",
        "    # Build recommendation dictionary\n",
        "    recommendations = {\n",
        "        user_id: [item_ids[j] for j in np.argsort(similarity_matrix[i])[::-1][:top_k]]\n",
        "        for i, user_id in enumerate(user_ids)\n",
        "    }\n",
        "\n",
        "    return recommendations\n"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1742301525270
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**State-of-the-Art Ranking Model (LambdaMART)**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "\n",
        "def train_lambdamart_ranking(user_embeddings_df, item_embeddings_df, relevance_dict):\n",
        "    features = []\n",
        "    labels = []\n",
        "    group_sizes = []\n",
        "\n",
        "    # Step 1: Filter relevance_dict to include only training users\n",
        "    training_users = set(user_embeddings_df.index)\n",
        "    filtered_relevance = {u: items for u, items in relevance_dict.items() if u in training_users}\n",
        "\n",
        "    for user_id, item_labels in filtered_relevance.items():\n",
        "        user_vec = user_embeddings_df.loc[user_id].values\n",
        "        valid_item_count = 0\n",
        "\n",
        "        for item_id, label in item_labels.items():\n",
        "            if item_id not in item_embeddings_df.index:\n",
        "                print(f\"Item ID {item_id} not in item_embeddings. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            item_vec = item_embeddings_df.loc[item_id].values\n",
        "\n",
        "            if user_vec.shape[0] != item_vec.shape[0]:\n",
        "                print(f\"Dimension mismatch: user {user_id}, item {item_id}. Skipping this pair.\")\n",
        "                continue\n",
        "\n",
        "            sim = cosine_similarity([user_vec], [item_vec])[0][0]\n",
        "            feature = np.concatenate([user_vec, item_vec, [sim]])\n",
        "            features.append(feature)\n",
        "            labels.append(label)\n",
        "            valid_item_count += 1\n",
        "\n",
        "        if valid_item_count > 0:\n",
        "            group_sizes.append(valid_item_count)\n",
        "\n",
        "    if not features:\n",
        "        raise ValueError(\"No valid training data could be constructed.\")\n",
        "\n",
        "    train_data = lgb.Dataset(np.array(features), label=np.array(labels), group=group_sizes)\n",
        "\n",
        "    params = {\n",
        "        'objective': 'lambdarank',\n",
        "        'metric': 'ndcg',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'learning_rate': 0.05,\n",
        "        'num_leaves': 32,\n",
        "        'min_data_in_leaf': 10\n",
        "    }\n",
        "\n",
        "    model = lgb.train(params, train_data, num_boost_round=100)\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict_lambdamart_ranking(model, user_embeddings_df, item_embeddings_df, relevance_dict, top_k=10):\n",
        "    \"\"\"\n",
        "    Predict top-k items per user using a trained LambdaMART model.\n",
        "\n",
        "    Args:\n",
        "        model (lightgbm.Booster): Trained model.\n",
        "        user_embeddings_df (pd.DataFrame): User embeddings indexed by user_id.\n",
        "        item_embeddings_df (pd.DataFrame): Item embeddings indexed by item_id.\n",
        "        relevance_dict (dict): {user_id: {item_id: relevance_label (0/1)}}\n",
        "        top_k (int): Number of items to recommend per user.\n",
        "\n",
        "    Returns:\n",
        "        dict: {user_id: [item_id1, item_id2, ...]} with top-k ranked items.\n",
        "    \"\"\"\n",
        "    recommendations = {}\n",
        "\n",
        "    for user_id, item_labels in relevance_dict.items():\n",
        "        user_vec = user_embeddings_df.loc[user_id].values\n",
        "        item_ids = list(item_labels.keys())\n",
        "\n",
        "        features = []\n",
        "        for item_id in item_ids:\n",
        "            item_vec = item_embeddings_df.loc[item_id].values\n",
        "            sim = cosine_similarity([user_vec], [item_vec])[0][0]\n",
        "            feature = np.concatenate([user_vec, item_vec, [sim]])\n",
        "            features.append(feature)\n",
        "\n",
        "        scores = model.predict(np.array(features))\n",
        "        ranked_items = [item for _, item in sorted(zip(scores, item_ids), reverse=True)[:top_k]]\n",
        "        recommendations[user_id] = ranked_items\n",
        "\n",
        "    return recommendations\n"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1742301691785
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_ranking_metrics(recommendations, relevance_dict, k_list=[5, 10, 20]):\n",
        "    \"\"\"\n",
        "    Compute Precision@k, Recall@k, and NDCG@k for multiple values of k.\n",
        "\n",
        "    Args:\n",
        "        recommendations (dict): {user_id: [ranked list of item_ids]}\n",
        "        relevance_dict (dict): {user_id: {item_id: relevance (0/1)}}\n",
        "        k_list (list): List of cutoff values for evaluation metrics.\n",
        "\n",
        "    Returns:\n",
        "        dict: Mean Precision@k, Recall@k, and NDCG@k for each k across all users.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for k in k_list:\n",
        "        precision_scores = []\n",
        "        recall_scores = []\n",
        "        ndcg_scores = []\n",
        "\n",
        "        for user_id, rec_items in recommendations.items():\n",
        "            if user_id not in relevance_dict:\n",
        "                continue\n",
        "\n",
        "            # Relevant (positive) items for the user\n",
        "            relevant_items = [item for item, rel in relevance_dict[user_id].items() if rel > 0]\n",
        "            if not relevant_items:\n",
        "                continue\n",
        "\n",
        "            # Top-k recommended items\n",
        "            top_k_items = rec_items[:k]\n",
        "            relevance = [1 if item in relevant_items else 0 for item in top_k_items]\n",
        "\n",
        "            # Precision@k\n",
        "            precision = sum(relevance) / k\n",
        "            precision_scores.append(precision)\n",
        "\n",
        "            # Recall@k\n",
        "            recall = sum(relevance) / len(relevant_items)\n",
        "            recall_scores.append(recall)\n",
        "\n",
        "            # NDCG@k\n",
        "            predicted_scores = list(range(k, 0, -1))  # descending scores\n",
        "            try:\n",
        "                ndcg = ndcg_score([relevance], [predicted_scores], k=k)\n",
        "                ndcg_scores.append(ndcg)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Store average metrics for current k\n",
        "        results[f\"Precision@{k}\"] = np.mean(precision_scores) if precision_scores else 0.0\n",
        "        results[f\"Recall@{k}\"] = np.mean(recall_scores) if recall_scores else 0.0\n",
        "        results[f\"NDCG@{k}\"] = np.mean(ndcg_scores) if ndcg_scores else 0.0\n",
        "\n",
        "    return results"
      ],
      "outputs": [],
      "execution_count": 86,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1742345408809
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "num_retrieval = 50\n",
        "num_recommend = 20\n",
        "num_eval = [1, 5, 10]\n",
        "\n",
        "# Zip user_id and user_summary into key-value pairs\n",
        "users_summary = dict(zip(user_df['user_id'], user_df['summary']))\n",
        "\n",
        "# Zip item_id and item_summary into key-value pairs\n",
        "items_summary = dict(zip(item_df['item_id'], item_df['summary']))\n",
        "\n",
        "# Generate embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings for users and items\n",
        "user_emb_array = model.encode(user_df['summary'].tolist())\n",
        "item_emb_array = model.encode(item_df['summary'].tolist())\n",
        "\n",
        "# Convert embeddings into DataFrames with index\n",
        "user_embeddings = pd.DataFrame(user_emb_array, index=user_df['user_id'])\n",
        "item_embeddings = pd.DataFrame(item_emb_array, index=item_df['item_id'])\n",
        "\n",
        "# Split users into train and test sets\n",
        "train_users, test_users = train_test_split(user_df['user_id'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract corresponding embeddings\n",
        "train_user_embeddings = user_embeddings.loc[train_users]\n",
        "test_user_embeddings = user_embeddings.loc[test_users]\n",
        "\n",
        "retrieval_set = compute_retrieval_set(user_embeddings, item_embeddings, k=num_retrieval)\n",
        "relevance_label = batch_label_user_interest(users_summary, items_summary, retrieval_set)\n",
        "\n",
        "recommend_similarity = recommend_top_k_items(user_embeddings, item_embeddings, top_k=num_recommend)\n",
        "\n",
        "lambdamart = train_lambdamart_ranking(train_user_embeddings, item_embeddings, relevance_label)\n",
        "recommend_lambdamart = predict_lambdamart_ranking(lambdamart, user_embeddings, item_embeddings, relevance_label, top_k=num_recommend)\n",
        "\n",
        "metrics_similarity = evaluate_ranking_metrics(recommend_similarity, relevance_label, num_eval)\n",
        "\n",
        "metrics_lambdamart = evaluate_ranking_metrics(recommend_lambdamart, relevance_label, num_eval)\n",
        "\n",
        "# Serialize both results\n",
        "results_combined = {\n",
        "    \"similarity\": metrics_similarity,\n",
        "    \"lambdamart\": metrics_lambdamart\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "with open(\"personalized_ranking.json\", \"w\") as f:\n",
        "    json.dump(results_combined, f, indent=4)\n",
        "\n",
        "print(\"Saved results to recommendation_results.json\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025-03-19 01:51:01,877 - INFO - Use pytorch device_name: cpu\n2025-03-19 01:51:01,878 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-03-19 01:51:01,886 - DEBUG - Resetting dropped connection: huggingface.co\n2025-03-19 01:51:01,938 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 200 0\n2025-03-19 01:51:01,955 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1\" 200 0\n2025-03-19 01:51:01,972 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1\" 200 0\n2025-03-19 01:51:01,987 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 200 0\n2025-03-19 01:51:02,003 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1\" 200 0\n2025-03-19 01:51:02,023 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1\" 404 0\n2025-03-19 01:51:02,051 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1\" 200 0\n2025-03-19 01:51:02,093 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n2025-03-19 01:51:02,160 - DEBUG - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1\" 200 6756\n2025-03-19 01:51:02,181 - DEBUG - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1\" 200 6756\nBatches: 100%|██████████| 1/1 [00:00<00:00, 19.56it/s]\nBatches: 100%|██████████| 66/66 [00:51<00:00,  1.28it/s]\n2025-03-19 01:51:53,748 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'For each of the following user and article pairs, determine interest level.\\nRespond only with a single line per pair, format:\\n`user_id, item_id, 1` for Interested OR `user_id, item_id, 0` for Not Interested.\\nDo NOT add extra explanations or formatting.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: e6994dcbb3\\nArticle: Millan says they want to include more music and more news from the world of Spanish language hip-hop and rap.The name says it all: it is web-based radio, devoted to the hottest Spanish language rap and hip-hop tracks.\"You can\\'t really just go on the radio and listen to hip-hop in Spanish... it\\'s just not accessible,\" says Manuel Millan, a native of San Diego, California.His name is Tote King and Manuel Millan says that he is the hip-hop leader in Spain.Millan says that Spain is actually just behind the United States and France in terms of overall rap and hip-hop production.The web might be just the right medium for Spanish language hip-hop right now.\"It\\'s really hard for the Spanish hip-hop scene to get into mainstream radio.That is not surprising as many consider Spain to be the leader in Spanish-language rap and hip-hop.\"He\\'s considered the Eminem of Argentina, and the Latin American hip-hop scene,\" Millan says.But what you will not find is much Spanish-language hip-hop.Los Caballeros de Plan G are one of Mexico\\'s hottest hip-hop acts.Hip-hop and rap are actually quite popular in the Spanish-speaking world, but local artists are having trouble marketing their work abroad.But most Mexican hip-hop fans, not to mention fans in most of the Spanish-speaking world, rarely get a chance to hear the group\\'s tracks on the radio.\"It\\'s basically him bragging that he\\'s one of the best emcees in Spain right now,\" Millan says.The site has listeners from across the Spanish speaking world.But now, a US company is bringing rap and hip-hop en espanol to computer users everywhere.Mustafa Yoda is currently one of the hottest tracks on latinohiphopradio.com.Millan and two friends set out to change that - they wanted to make groups like Los Caballeros de Plan G accessible to fans globally.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 563304339f\\nArticle: \"Bob was a good player.That was the end of it.\"The last time I saw him was in London in 1980.Bob was a very driven individual.: \"Bob was endlessly optimistic about the way Africa would turn out.It was one of the last dates he did in London.\"At the risk of stating the obvious, he was an extraordinary song writer and his stage act was perhaps the greatest I\\'ve ever seen.It was interrupted to do a rehearsal.: Bob was one of the most mesmeric people I\\'ve ever had the privilege to work with.\"By 1979 he was the biggest touring attraction in the world.He was an attacking midfield player.: Well 1981 was to be the year he toured Africa with Stevie Wonder.: It was always a struggle for him to connect with Black America.I had no sense his career was going to go downhill.\"We can\\'t speculate but he was at the height of his powers and just 36 years old.: \"The final tune of his final album was Redemption Song - one of the most incredible classics of all time.\"\"He sat down in front of the TV and after 10 minutes it was obvious he wasn\\'t going to move.You realised from the start there was a manifest destiny within him that he believed in.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: c32e4f2d2a\\nArticle: The tsunami tribute song will also feature Alicia Keys, Velvet Revolver and Tim McGraw.The awards show will also feature performances from U2, Green Day, Alicia Keys and Kanye West - but the Lopez and Anthony duet is likely to be one of the biggest talking points.Singers Jennifer Lopez and husband Marc Anthony, a Latin pop star, are to perform a duet at this month\\'s Grammy Awards in Los Angeles.Anthony became Lopez\\'s third husband in June 2004.There will also be a tribute to Ray Charles featuring Bonnie Raitt and Billy Preston and a celebration of southern rock with Tim McGraw, Gretchen Wilson, Lynyrd Skynyrd, Dickie Betts and Elvis Bishop.He is nominated this year for best Latin pop album and best salsa/merengue album.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: af1ce47f4b\\nArticle: Mr Fischer will face a delicate balancing act - both in political and economic terms - between Mr Sharon and finance minister Binyamin Netanyahu, who also backed his nomination.But his appointment has also raised hopes that it could bring in fresh investment - and perhaps even an improvement in the country\\'s credit rating Mr Fischer first went to Israel for six months in 1973, and almost emigrated there before deciding finally to return to the US.Stanley Fischer, vice chairman of banking giant Citigroup, has agreed to take the Bank of Israel job subject to approval from parliament and cabinet.Israel has asked a US banker and former International Monetary Fund director to run its central bank.Mr Fischer, who speaks fluent Hebrew, will have to become an Israeli citizen to take the job.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: f6ef2fb276\\nArticle: Venezuela has previously assured foreign companies with operations in the mineral rich country that it respects existing contracts.President Hugo Chavez has ordered all existing contracts with foreign firms to be examined to see if they provide maximum benefits to the country.Announcing the review of raw material production, minister Victor Alvarez said the government would seek to transfer technology, training capability and content from projects with foreign partners.Venezuela is to review all foreign investment in its mining industries in an effort to strengthen its indigenous industrial output.Chavez has sought to extend the state\\'s role in all sectors of the economy.However, the government insisted that it needed to develop its own industrial infrastructure in order to create new jobs and lessen its reliance on foreign partners.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: dfd5f35fd9\\nArticle: Stuart has extensive top-flight experience with Everton, Chelsea and Charlton and can play across the midfield positions.Stuart, a former England Under-21 international, made 110 appearances for Chelsea, scoring 18 goals, before joining Everton.Norwich have signed Charlton midfielder Graham Stuart until the end of the season for an undisclosed fee.He joins Norwich with the Norfolk club second-from-bottom in the Premiership, but Stuart is confident that the Carrow Road outfit have a bright future.Stuart spent just over four years at Goodison Park, making 125 senior appearances and scoring 25 goals, before signing for Sheffield United - where he scored 12 goals in 68 appearances.Canaries boss Nigel Worthington added: \"I\\'m delighted that Graham will be joining us until the end of the season.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: f4c93fa0ea\\nArticle: Defiant Matt Williams says he will not quit as Scotland coach even if his side slump to a new low with defeat by Italy at Murrayfield.Williams has yet to experience an RBS Six Nations victory after seven attempts and Scotland have lost 12 of their 14 games under his leadership.Williams insists that he is revelling in the pressure, despite the possibility of a second Six Nations series without a victory.\"How can a German football coach and an Australian rugby coach have anything in common?\"\"But I actually really enjoy seeing how you cope with such pressure as a coach.\"There\\'s nothing much between the teams, so we could win the next three games or lose them.\"It helps the team grow and helps you grow as a coach.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: b67dc286c4\\nArticle: Right now, the Alert Retrieval Cache can only take a text message and automatically upload it to a web-page, or distribute it to an e-mail list.So Mr Senanayake started sending out text messages.Last week, he sent out e-mail messages asking for help in creating such a system for Asia.Thousands around the world followed the story that unfolded in the text messages that he sent.\"He can message the server, so the server can send out an e-mail message and human or machine moderators can e-mail aid agencies and get it out in the field.\"In the near future, the group says it hopes to take in messages from people in affected areas, and use human moderators to take actions based on the content of those messages.Mr Rampersad said: \"Imagine if an aid worker in the field spotted a need for water purification tablets, and had a central place to send a text message to that effect.He wondered if there might be a way to automatically centralise text messages, and then redistribute them to agencies and people who might be able to help.The messages can get through even when the cell phone signal is too weak to sustain a spoken conversation.And that\\'s when Mr Senanayake started to wonder if SMS might be put to more practical use.Blogging friends in India took Mr Senanayake\\'s text messages and posted them on a weblog called Dogs without Borders.\"SMS networks can handle so much more traffic than the standard mobile phone call or the land line call,\" he says.In only 72 hours, he found Dan Lane, a text message guru living in Britain.You have to get people to know that the system is there for them to use.\"You may be halfway around the world from someone, but in cyberspace you\\'re just one click or one e-mail away,\" he said, \"That\\'s put a whole new dimension on disaster relief and recovery, where often people halfway around the world can be more effective in making something happen precisely because they\\'re not right on top of the tragedy.\"Mr Rampersad, who used to work in the military, knew how important on the ground communication can be in times of disaster.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 2650f559db\\nArticle: \"I\\'m happy Madrid is interested in me because it has always been my dream since I was little to play there.\"Jose Antonio Reyes has added to speculation linking him with a move from Arsenal to Real Madrid after falling victim to a radio prank.\"I have seen the stories in the media linking me with Real Madrid,\" he had said on Thursday lunchtime.\"I wish I was playing for Real Madrid,\" the 21-year-old told Cadena Cope.\"If I\\'m not (playing for Real) I\\'m going to have to carry on playing with some bad people,\" he added.The Spaniard believed he was talking to Real Madrid sporting director Emilio Butragueno when he allegedly berated his team-mates as \"bad people\".I love the way Madrid play.I\\'m not happy with the way things are.\"\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 57af0fce80\\nArticle: Bolton boss Sam Allardyce has signed Roma defender Vincent Candela on a five-month deal.\"In light of what has happened to Nicky Hunt, with his injury, it might be a blessing in disguise that we can bring in a highly-experienced full-back to help with our injuries at the back,\" Allardyce said.\"He has an outstanding pedigree in the game and has won honours at the highest level including the World Cup in 1998.\"He has not played regular football this year but is eager to impress in the Premiership.\\n\\n'}], 'model': 'gpt-4o-mini', 'temperature': 0.3}}\n2025-03-19 01:51:53,751 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n2025-03-19 01:51:53,752 - DEBUG - close.started\n2025-03-19 01:51:53,753 - DEBUG - close.complete\n2025-03-19 01:51:53,754 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n2025-03-19 01:51:53,759 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe06886cc10>\n2025-03-19 01:51:53,760 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe069bf8140> server_hostname='api.openai.com' timeout=5.0\n2025-03-19 01:51:53,770 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe06886c130>\n2025-03-19 01:51:53,771 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n2025-03-19 01:51:53,772 - DEBUG - send_request_headers.complete\n2025-03-19 01:51:53,773 - DEBUG - send_request_body.started request=<Request [b'POST']>\n2025-03-19 01:51:53,774 - DEBUG - send_request_body.complete\n2025-03-19 01:51:53,775 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n2025-03-19 01:51:56,546 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 01:51:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gbgqrr8mnjzeosnimrnxpaf7'), (b'openai-processing-ms', b'2652'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1996847'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'94ms'), (b'x-request-id', b'req_62f88e1515410e154b685d0311bfde1f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Z7QK_twf5kPsgkzsQOp19Rep7ELj7K0U1BYONjtPgbQ-1742349116-1.0.1.1-8H6g34b7Ee3Cn1K0IDRFTg8lIzvvlhJlkYGT6sOA0Ydj4zqVL_LXBammG5GUvKDZFhB2lCIvg4np3q15oqn.vBMKRjqeqB6PitVvTxEvRko; path=/; expires=Wed, 19-Mar-25 02:21:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922953c91dcd07e1-IAD'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n2025-03-19 01:51:56,547 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-03-19 01:51:56,548 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n2025-03-19 01:51:56,551 - DEBUG - receive_response_body.complete\n2025-03-19 01:51:56,551 - DEBUG - response_closed.started\n2025-03-19 01:51:56,552 - DEBUG - response_closed.complete\n2025-03-19 01:51:56,552 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 19 Mar 2025 01:51:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-gbgqrr8mnjzeosnimrnxpaf7', 'openai-processing-ms': '2652', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '1996847', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '94ms', 'x-request-id': 'req_62f88e1515410e154b685d0311bfde1f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Z7QK_twf5kPsgkzsQOp19Rep7ELj7K0U1BYONjtPgbQ-1742349116-1.0.1.1-8H6g34b7Ee3Cn1K0IDRFTg8lIzvvlhJlkYGT6sOA0Ydj4zqVL_LXBammG5GUvKDZFhB2lCIvg4np3q15oqn.vBMKRjqeqB6PitVvTxEvRko; path=/; expires=Wed, 19-Mar-25 02:21:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '922953c91dcd07e1-IAD', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n2025-03-19 01:51:56,553 - DEBUG - request_id: req_62f88e1515410e154b685d0311bfde1f\n2025-03-19 01:51:56,558 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'For each of the following user and article pairs, determine interest level.\\nRespond only with a single line per pair, format:\\n`user_id, item_id, 1` for Interested OR `user_id, item_id, 0` for Not Interested.\\nDo NOT add extra explanations or formatting.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 8f33feb203\\nArticle: Former Labour leader Neil Kinnock has officially been made a life peer during a ceremony in the House of Lords.During his induction into the Upper House, Lord Kinnock was accompanied by Lords Leader Baroness Amos and Baroness Royall of Blaisdon, a former aide to the ex-Labour leader.Lord Kinnock - who led Labour from 1983 until 1992 - was until recently one of Britain\\'s EU commissioners.A former critic of the House of Lords, he has said he will use the Upper House to advocate its reform and to talk on issues like higher education.It has been a long journey for the new Lord Kinnock from his earliest days as a rebellious youngster in the south Wales valleys.He will be known Baron Kinnock of Bedwellty - after his former constituency.As he assumes the title of Lord Kinnock, he has also become chairman of the British Council, which promotes the UK\\'s reputation for arts, science and education.\"I accepted the kind invitation to enter the House of Lords as a working peer for practical political reasons,\" he said when his peerage was first announced.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 3995700fcb\\nArticle: Day has been displaced by the arrival of Simon Royce, who is in his second month on loan from Charlton.Queens Park Rangers keeper Chris Day is set to join Preston on a month\\'s loan.Meanwhile, Holloway is hoping to complete the signing of Middlesbrough defender Andy Davies - either permanently or again on loan - before Saturday\\'s match at Ipswich.R\\'s manager Ian Holloway said: \"Some might say it\\'s a risk as he can\\'t be recalled during that month and Simon Royce can now be recalled by Charlton.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 91e47c6049\\nArticle: Alberto Flores, president of the Spanish FA\\'s disciplinary committee, said no-one in the committee felt Aragones was a racist nor had \"acted in a racist way.\"\"You compare his fine and my fine, and if you consider his was for racist abuse, then you seem to get away with it more in Spain than you should,\" Wenger said.Aragones was handed the fine on Tuesday after making racist remarks about Henry to Arsenal team-mate and Spanish international Jose Reyes last October.The Spanish Football Federation at first declined to take action against Aragones, but was then requested to do so by Spain\\'s anti-violence commission.Arsenal boss Arsene Wenger, who was fined £15,000 in December for accusing Manchester United striker Ruud van Nistelrooy of cheating, believes that Aragones\\' punishment was too lenient.The fine was far less than the expected amount of about £22,000 or even the suspension of his coaching licence.However, Aragones insists the fine is unjustified and unfair.Spain coach Luis Aragones is furious after being fined by The Spanish Football Federation for his comments about Thierry Henry.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 09e15fc644\\nArticle: Moya led Spain to victory over the USA but wants to focus on the Grand Slams in 2005, although insists he will return to the Davis Cup in 2006.Carlos Moya has chosen not to help Spain try and defend the Davis Cup crown they won in Seville in November.\"Since the Davis Cup in Seville I have been working on my condition as well as technical and medical aspects of my game which will allow me to come into the big events of the year in top form.\"\"After two years of total commitment with the Davis Cup team...\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 2b4e2f909a\\nArticle: \\'\\'Robbie has an agreement with Larne that he can negotiate with interested clubs.But it would be great to see him making it at Sunderland.\\'\\'\"I heard on Sunday that he has joined Sunderland, but not from the lad himself,\" he said.\\'\\'He has been on trial with a number of clubs.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: d022561704\\nArticle: Speaking to the Radio Times, the Two Ronnies star said there is too much bad language and reality TV.Corbett said he and Barker were always mindful of their family audience while making The Two Ronnies.Corbett, soon to reunite with Ronnie Barker for a new Two Ronnies series, also criticised quiz shows like the BBC\\'s They Think It\\'s All Over.Corbett is the latest comedy star to bemoan the \"dumbing down\" of modern TV programmes.said the 74-year-old comedian.Ronnie Corbett has joined fellow comedy stars Victoria Wood and David Jason in attacking the declining standards of British television programmes.\"Our material was good-natured,\" he said.Corbett goes on to criticise \"reality programmes where they put people in a house for a fortnight and film them doing everything\".Its bespectacled stars will return later this year in The Two Ronnies Sketchbook, which will combine classic sketches with newly recorded material.\"We\\'ve got to be careful not to dumb down for the audience,\" he said.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 2cfb9977b8\\nArticle: Collins has played rugby at regional level, was captain of the Great Britain American Football team, and competed at national level in judo and karate.Collins said: \"It\\'s a great challenge.UK Athletics has ended its search for a new performance director by appointing psychologist Dave Collins.Collins, who worked with the British teams at the 2000 and 2004 Olympics, takes over from Max Jones.He has specialised in helping competitors fulfil their potential through psychology and has worked with the Great Britain women\\'s curling team, who won gold at the 2002 Winter Olympics.The appointment of a new performance director was one of the main recommendations in Sir Andrew Foster\\'s review of the sport, which was published in May.It was commissioned by UK Sport and Sport England, which wanted UK Athletics to justify funding of more than £40m from the Government following the failure to hang on to the 2005 World Championships, which are now being held in Helsinki.\"The appointment of David Collins, with his strong mix of leadership skills and managerial experience, is testament to the professional and detailed recruitment process,\" he said.He is currently professor of physical education and sport performance at Edinburgh University, where he helps competitors across many sports, including rugby, athletics, judo and football.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 634cba9ed1\\nArticle: Rapper Young Buck has been charged after allegedly stabbing a man who hit Dr Dre as he was about to receive a lifetime achievement award.Mr Johnson allegedly approached Dr Dre, who was seated at a table in front of the stage, and appeared to ask for an autograph before punching him.During the ensuing scuffle - which involved many of the 1,000-strong crowd - Mr Johnson was stabbed as he was being dragged away by security staff,Vibe magazine president Kenard Gibbs said the attack earlier this month in Santa Monica was \"sickening\".\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: 309941a853\\nArticle: Toulouse\\'s former Irish international Trevor Brennan could be one of Clive Woodward\\'s many surprises when the 44-man Lions tour squad is announced.\"If you speak to the players there\\'s a huge amount of respect for the guy,\" Woodward told the Sunday Independent.\"I\\'ve spoken to quite a few players, and they probably don\\'t know what they\\'re actually saying when we\\'re having these conversations,\" he told the newspaper.It\\'s not just the Irish, but Welsh and English players as well.\"Brennan, who last played for Ireland against Samoa in 2001, is held in high esteem by the former England coach.\\n\\nUser ID: 1a346b79\\nProfile: Robert Garcia is a Administrator, Civil Service who enjoys language learning, baking, singing and specializes in similar, plant, lawyer, beat, current.\\nArticle ID: a8a3503a52\\nArticle: The Police Federation has said it strongly opposes giving Community Support Officers (CSOs) the power to detain suspects for up to 30 minutes.Police Federation chairman Jan Berry said civilian officers should act as \"eyes and ears\" for the police.She said more powers would mean more paperwork and less time on the street.But the government said the move would help police \"build safe communities\".\"The powers that we are bringing in are things that they need to do when they are out patrolling,\" she said.Ms Blears said the study shows CSOs are \"making a real difference\" in the fight against crime.She denied their role was changing and said the new powers would not take them away from the streets.Shadow home secretary David Davis said the research appeared to acknowledge that CSOs were having no discernible effect on crime figures.The federation said CSOs do not have the experience, training and safety equipment to deal with \"potentially confrontational\" situations.\\n\\n'}], 'model': 'gpt-4o-mini', 'temperature': 0.3}}\n2025-03-19 01:51:56,559 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n2025-03-19 01:51:56,560 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n2025-03-19 01:51:56,560 - DEBUG - send_request_headers.complete\n2025-03-19 01:51:56,561 - DEBUG - send_request_body.started request=<Request [b'POST']>\n2025-03-19 01:51:56,561 - DEBUG - send_request_body.complete\n2025-03-19 01:51:56,562 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n"
        }
      ],
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1742345520154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}