{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Multimodal Recommendation Study using CLIP Embeddings\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "This tutorial combines effective prompting techniques with an end-to-end workflow for personalized product recommendations. You will learn how to design a recommendation system using an LLM that recommends products based on a user's preferences."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, ndcg_score\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ======================\n",
        "# 1. Setup & Load CLIP\n",
        "# ======================\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1743040069738
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Load Dataset and Preprocessing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Extract a representative large image URL (first non-null entry from 'images.large')\n",
        "def extract_image_url(images_dict):\n",
        "    try:\n",
        "        large_imgs = images_dict.get('large', [])\n",
        "        for url in large_imgs:\n",
        "            if isinstance(url, str) and url.startswith(\"http\"):\n",
        "                return url\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def process_data_sample(dataset_str, review_key, meta_key, sampling_percent=1.0):\n",
        "    \"\"\"\n",
        "    Load and process Amazon reviews and metadata, sample a percentage of reviews, and return interactions and product metadata.\n",
        "\n",
        "    Args:\n",
        "        dataset_str (str): Hugging Face dataset path (e.g., \"McAuley-Lab/Amazon-Reviews-2023\")\n",
        "        review_key (str): Subset key for reviews (e.g., \"raw_review_Books\")\n",
        "        meta_key (str): Subset key for metadata (e.g., \"raw_meta_Books\")\n",
        "        sampling_percent (float): Percentage of data to load (e.g., 1.0 for 1%)\n",
        "\n",
        "    Returns:\n",
        "        interaction_df (pd.DataFrame): Processed review interactions with user/item/rating info\n",
        "        product_df (pd.DataFrame): Product metadata including item_id, title, category\n",
        "    \"\"\"\n",
        "\n",
        "    # Load sampled user reviews\n",
        "    split_str = f\"full[:{sampling_percent}%]\"\n",
        "    reviews = load_dataset(dataset_str, review_key, split=split_str, trust_remote_code=True)\n",
        "    reviews_df = pd.DataFrame(reviews)\n",
        "\n",
        "    # Select and rename relevant review columns\n",
        "    reviews_df = reviews_df[['user_id', 'parent_asin', 'timestamp', 'rating', 'verified_purchase']]\n",
        "    reviews_df.rename(columns={\n",
        "        'parent_asin': 'item_id'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Define interaction type\n",
        "    def define_label(row):\n",
        "        if row['rating'] >= 4:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    reviews_df['label'] = reviews_df.apply(define_label, axis=1)\n",
        "    # reviews_df['timestamp'] = pd.to_datetime(reviews_df['timestamp'], unit='s')\n",
        "\n",
        "    # Load full metadata\n",
        "    metadata = load_dataset(dataset_str, meta_key, split=\"full\", trust_remote_code=True)\n",
        "    metadata_df = pd.DataFrame(metadata)\n",
        "    # print(metadata_df.head())\n",
        "    # Add 'image_url' field\n",
        "    metadata_df['image_url'] = metadata_df['images'].apply(extract_image_url)\n",
        "\n",
        "    # Process metadata and keep relevant fields\n",
        "    metadata_df = metadata_df[['parent_asin', 'title', 'main_category', 'categories', 'image_url']]\n",
        "    metadata_df.rename(columns={\n",
        "        'parent_asin': 'item_id'\n",
        "    }, inplace=True)\n",
        "        \n",
        "    # Merge review and product metadata\n",
        "    interaction_df = reviews_df.merge(metadata_df, on='item_id', how='left')\n",
        "\n",
        "    return interaction_df, metadata_df\n"
      ],
      "outputs": [],
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1743040069879
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def prepare_pairwise_ranking_data_with_user_split(user_df, product_df, test_ratio=0.2, num_negatives=1, seed=42):\n",
        "    \"\"\"\n",
        "    Perform train/test split within each user, keeping only users with ≥5 interactions,\n",
        "    then generate pairwise ranking pairs.\n",
        "\n",
        "    Args:\n",
        "        user_df: Interaction DataFrame with ['user_id', 'item_id', 'label']\n",
        "        product_df: Product DataFrame (used for item matching if needed)\n",
        "        test_ratio: Proportion of each user's interactions to hold out for test\n",
        "        num_negatives: Number of negative samples per positive\n",
        "        seed: Random seed\n",
        "\n",
        "    Returns:\n",
        "        train_df, test_df: DataFrames\n",
        "        train_pairs, test_pairs: List of (user_id, pos_item, neg_item)\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    train_rows, test_rows = [], []\n",
        "\n",
        "    for user_id, group in user_df.groupby(\"user_id\"):\n",
        "        if len(group) < 5:\n",
        "            continue  # Skip users with too few interactions\n",
        "\n",
        "        group = group.sample(frac=1, random_state=seed)  # Shuffle interactions\n",
        "        split_idx = int(len(group) * (1 - test_ratio))\n",
        "\n",
        "        train_rows.append(group.iloc[:split_idx])\n",
        "        test_rows.append(group.iloc[split_idx:])\n",
        "\n",
        "    train_df = pd.concat(train_rows)\n",
        "    test_df = pd.concat(test_rows)\n",
        "\n",
        "    def generate_pairs(interactions, num_negatives=1, max_pairs_per_user=5):\n",
        "        pairs = []\n",
        "        grouped = interactions.groupby(\"user_id\")\n",
        "        for user_id, group in grouped:\n",
        "            pos_items = group[group['label'] == 1]['item_id'].tolist()\n",
        "            neg_items = group[group['label'] == 0]['item_id'].tolist()\n",
        "            if len(pos_items) == 0 or len(neg_items) == 0:\n",
        "                continue\n",
        "\n",
        "            user_pairs = []\n",
        "            for pos in pos_items:\n",
        "                sampled_negs = random.sample(neg_items, min(len(neg_items), num_negatives))\n",
        "                for neg in sampled_negs:\n",
        "                    user_pairs.append((user_id, pos, neg))\n",
        "\n",
        "            # Limit number of pairs per user\n",
        "            sampled_user_pairs = random.sample(user_pairs, min(len(user_pairs), max_pairs_per_user))\n",
        "            pairs.extend(sampled_user_pairs)\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    train_pairs = generate_pairs(train_df, num_negatives)\n",
        "    test_pairs = generate_pairs(test_df, num_negatives)\n",
        "\n",
        "    return train_df, test_df, train_pairs, test_pairs\n"
      ],
      "outputs": [],
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1743040070034
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Feature Extraction\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# ======================\n",
        "# Feature Extraction Module\n",
        "# ======================\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, clip_model, clip_processor, device='cpu'):\n",
        "        self.clip_model = clip_model\n",
        "        self.clip_processor = clip_processor\n",
        "        self.device = device\n",
        "        \n",
        "    def get_text_embeddings(self, texts, batch_size=32):\n",
        "        \"\"\"Extract CLIP text embeddings\"\"\"\n",
        "        all_embeddings = []\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            inputs = self.clip_processor(text=batch, return_tensors=\"pt\", \n",
        "                                       padding=True, truncation=True).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                emb = self.clip_model.get_text_features(**inputs)\n",
        "            all_embeddings.append(emb.cpu())\n",
        "        return torch.cat(all_embeddings)\n",
        "\n",
        "    def get_image_embeddings(self, image_urls, batch_size=16):\n",
        "        embeddings = []\n",
        "        for i in range(0, len(image_urls), batch_size):\n",
        "            batch = image_urls[i:i+batch_size]\n",
        "            images = []\n",
        "            for url in batch:\n",
        "                try:\n",
        "                    response = requests.get(url, timeout=5)\n",
        "                    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "                    images.append(img)\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Failed to load image from {url} — {e}\")\n",
        "                    # Add a dummy black image of standard size\n",
        "                    images.append(Image.new(\"RGB\", (224, 224), color=(0, 0, 0)))\n",
        "\n",
        "            inputs = self.clip_processor(images=images, return_tensors=\"pt\").to(self.device)\n",
        "            with torch.no_grad():\n",
        "                image_emb = self.clip_model.get_image_features(**inputs)\n",
        "            image_emb = image_emb / image_emb.norm(p=2, dim=-1, keepdim=True)\n",
        "            embeddings.append(image_emb.cpu())\n",
        "        return torch.cat(embeddings, dim=0)\n",
        "\n",
        "    def get_multimodal_embeddings(self, product_df, ablation = False):\n",
        "        \"\"\"Combine text and image embeddings and return with product_df index.\"\"\"\n",
        "        product_df['title'] = product_df['title'].fillna(\"\")\n",
        "        text_emb = self.get_text_embeddings(product_df['title'].tolist())\n",
        "        image_emb = self.get_image_embeddings(product_df['image_url'].tolist())\n",
        "\n",
        "        multimodal_emb = (text_emb + image_emb) / 2\n",
        "        if ablation:\n",
        "            multimodal_emb = text_emb\n",
        "\n",
        "        # Return as pandas DataFrame indexed by product_df.index\n",
        "        return pd.DataFrame(multimodal_emb.numpy(), index=product_df['item_id'])\n",
        "\n",
        "    def create_user_embeddings(self, user_df, product_embeddings, product_df=None, positive_only=True):\n",
        "        \"\"\"\n",
        "        Create user embeddings by aggregating the embeddings of positively interacted items.\n",
        "\n",
        "        Args:\n",
        "            user_df (pd.DataFrame): User interactions with 'user_id', 'item_id', and optionally 'rating' or 'label'.\n",
        "            product_embeddings (pd.DataFrame): Embeddings indexed by 'item_id'.\n",
        "            product_df (pd.DataFrame, optional): Product metadata for fallback.\n",
        "            positive_only (bool): Whether to include only positive interactions.\n",
        "\n",
        "        Returns:\n",
        "            dict: Mapping from user_id to aggregated embedding tensor.\n",
        "        \"\"\"\n",
        "        user_embeddings = {}\n",
        "        embedding_dim = product_embeddings.shape[1]\n",
        "        \n",
        "        # Filter to only positive interactions if applicable\n",
        "        if positive_only:\n",
        "            if \"rating\" in user_df.columns:\n",
        "                user_df = user_df[user_df[\"rating\"] >= 4]\n",
        "            elif \"label\" in user_df.columns:\n",
        "                user_df = user_df[user_df[\"label\"] == 1]\n",
        "\n",
        "        grouped = user_df.groupby('user_id')\n",
        "\n",
        "        for user_id, group in grouped:\n",
        "            item_ids = group['item_id'].unique()\n",
        "\n",
        "            # Retain only those items with valid embeddings\n",
        "            available_ids = [item_id for item_id in item_ids if item_id in product_embeddings.index]\n",
        "\n",
        "            if not available_ids:\n",
        "                user_embeddings[user_id] = torch.zeros(embedding_dim)\n",
        "                continue\n",
        "\n",
        "            # Aggregate using mean pooling\n",
        "            item_embs = product_embeddings.loc[available_ids].values\n",
        "            user_embeddings[user_id] = torch.tensor(item_embs).float().mean(dim=0)\n",
        "\n",
        "        return user_embeddings\n"
      ],
      "outputs": [],
      "execution_count": 78,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1743040070188
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Model Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# ======================\n",
        "# Model Definitions\n",
        "# ======================\n",
        "\n",
        "class RankingModel(nn.Module):\n",
        "    \"\"\"MLP-based ranking model\"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(dim * 2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, user_emb, item_emb):\n",
        "        x = torch.cat([user_emb, item_emb], dim=1)\n",
        "        return self.model(x)\n",
        "\n",
        "class DotProductModel(nn.Module):\n",
        "    \"\"\"Dot-product based ranking model\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, user_emb, item_emb):\n",
        "        return (user_emb * item_emb).sum(dim=1, keepdim=True)\n",
        "\n",
        "# ======================\n",
        "# BPR Loss Function\n",
        "# ======================\n",
        "\n",
        "def bpr_loss(pos_score, neg_score):\n",
        "    \"\"\"Bayesian Personalized Ranking loss\"\"\"\n",
        "    return -torch.log(torch.sigmoid(pos_score - neg_score)).mean()\n",
        "\n",
        "# ======================\n",
        "# Training Loop\n",
        "# ======================\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, device='cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "    def train(self, pairs, user_embeddings, product_embeddings, epochs=5):\n",
        "        for epoch in range(epochs):\n",
        "            losses = []\n",
        "            for user_id, pos_pid, neg_pid in tqdm(pairs):\n",
        "                try:\n",
        "                    # Retrieve embeddings\n",
        "                    user_vec = user_embeddings[user_id].unsqueeze(0).to(self.device)\n",
        "                    pos_vec = torch.tensor(product_embeddings.loc[pos_pid], dtype=torch.float32).unsqueeze(0).to(self.device)\n",
        "                    neg_vec = torch.tensor(product_embeddings.loc[neg_pid], dtype=torch.float32).unsqueeze(0).to(self.device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    pos_score = self.model(user_vec, pos_vec)\n",
        "                    neg_score = self.model(user_vec, neg_vec)\n",
        "\n",
        "                    # Compute BPR loss\n",
        "                    loss = bpr_loss(pos_score, neg_score)\n",
        "\n",
        "                    # Backward\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "                    losses.append(loss.item())\n",
        "                except KeyError:\n",
        "                    continue  # Skip if embeddings not found\n",
        "            \n",
        "            print(f\"Epoch {epoch+1}, Loss: {np.mean(losses):.4f}\")\n"
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1743040070328
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ======================\n",
        "# # Recommendation Module\n",
        "# # ======================\n",
        "# class Recommender:\n",
        "#     def __init__(self, model, user_embeddings, product_embeddings, device='cpu'):\n",
        "#         self.model = model.to(device)\n",
        "#         self.user_embeddings = user_embeddings\n",
        "#         self.product_embeddings = product_embeddings\n",
        "#         self.device = device\n",
        "        \n",
        "#     def recommend(self, user_id, top_k=10):\n",
        "#         \"\"\"Generate top-k recommendations for a user\"\"\"\n",
        "#         user_vec = self.user_embeddings[user_id].unsqueeze(0).to(self.device)\n",
        "#         item_vectors = self.product_embeddings.values.to(self.device)\n",
        "        \n",
        "#         # Calculate scores\n",
        "#         with torch.no_grad():\n",
        "#             repeated_user = user_vec.repeat(item_vectors.shape[0], 1)\n",
        "#             scores = self.model(repeated_user, item_vectors).squeeze()\n",
        "        \n",
        "#         # Get top-k indices\n",
        "#         _, indices = torch.topk(scores, top_k)\n",
        "#         return self.product_embeddings.index[indices.cpu().numpy()]\n"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "gather": {
          "logged": 1743040070452
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Model Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Evaluation Module\n",
        "# ======================\n",
        "class Evaluator:\n",
        "    def __init__(self, model, user_embeddings, product_embeddings, device='cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.user_embeddings = user_embeddings\n",
        "        self.product_embeddings = product_embeddings\n",
        "        self.device = device\n",
        "\n",
        "    def evaluate_pairwise(self, eval_pairs):\n",
        "        \"\"\"Evaluate pairwise ranking accuracy, skipping users without embeddings\"\"\"\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for user_id, pos_pid, neg_pid in eval_pairs:\n",
        "            if user_id not in self.user_embeddings:\n",
        "                continue  # Skip users without embeddings\n",
        "\n",
        "            try:\n",
        "                user_vec = self.user_embeddings[user_id].unsqueeze(0).to(self.device)\n",
        "                pos_vec = torch.tensor(self.product_embeddings.loc[pos_pid].values).unsqueeze(0).to(self.device)\n",
        "                neg_vec = torch.tensor(self.product_embeddings.loc[neg_pid].values).unsqueeze(0).to(self.device)\n",
        "            except KeyError:\n",
        "                continue  # Skip if product embeddings are missing\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pos_score = self.model(user_vec, pos_vec)\n",
        "                neg_score = self.model(user_vec, neg_vec)\n",
        "\n",
        "            correct += int(pos_score.item() > neg_score.item())\n",
        "            total += 1\n",
        "\n",
        "        return correct / total if total > 0 else 0.0\n"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "gather": {
          "logged": 1743040070571
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def run_ablation_experiment(ablation=False):\n",
        "    # 3. Feature extraction\n",
        "    fe = FeatureExtractor(clip_model, clip_processor, device)\n",
        "    product_embeddings = fe.get_multimodal_embeddings(product_df, ablation=ablation)\n",
        "\n",
        "    # 5. Create user representations\n",
        "    user_embeddings = fe.create_user_embeddings(train_df, product_embeddings, product_df)\n",
        "\n",
        "    # ========== 6. Initialize and train both models ==========\n",
        "\n",
        "    # Model A: MLP-based Ranking Model\n",
        "    mlp_model = RankingModel(product_embeddings.shape[1])\n",
        "    mlp_trainer = Trainer(mlp_model, device)\n",
        "    mlp_trainer.train(train_pairs, user_embeddings, product_embeddings, epochs=5)\n",
        "\n",
        "    # Model B: Dot Product Model\n",
        "    dot_model = DotProductModel()\n",
        "\n",
        "    # ========== 8. Evaluate Both Models ==========\n",
        "    mlp_evaluator = Evaluator(mlp_model, user_embeddings, product_embeddings, device)\n",
        "    dot_evaluator = Evaluator(dot_model, user_embeddings, product_embeddings, device)\n",
        "\n",
        "    mlp_trainaccuracy = mlp_evaluator.evaluate_pairwise(train_pairs)\n",
        "    dot_trainaccuracy = dot_evaluator.evaluate_pairwise(train_pairs)\n",
        "\n",
        "    mlp_accuracy = mlp_evaluator.evaluate_pairwise(test_pairs)\n",
        "    dot_accuracy = dot_evaluator.evaluate_pairwise(test_pairs)\n",
        "\n",
        "    # ========== Print Results ==========\n",
        "    print(\"========== Ablation:\", ablation, \"==========\")\n",
        "    print(f\"Train pairs: {len(train_pairs)}\")\n",
        "    print(f\"Test pairs: {len(test_pairs)}\")\n",
        "    print(f\"MLP Model Test Accuracy: {mlp_accuracy:.2f}\")\n",
        "    print(f\"Dot Product Model Test Accuracy: {dot_accuracy:.2f}\")\n",
        "\n",
        "    # ========== Save Results to JSON ==========\n",
        "    results_combined = {\n",
        "        \"ablation\": ablation,\n",
        "        \"MLP Model\": {\n",
        "            \"Accuracy\": mlp_accuracy,\n",
        "            \"Training Accuracy\": mlp_trainaccuracy,\n",
        "            \"Training pairs\": len(train_pairs)\n",
        "        },\n",
        "        \"DotProduct Model\": {\n",
        "            \"Accuracy\": dot_accuracy,\n",
        "            \"Training Accuracy\": dot_trainaccuracy,\n",
        "            \"Test pairs\": len(test_pairs)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    filename = f\"ablation_results_{'text_only' if ablation else 'multimodal'}.json\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(results_combined, f, indent=2)\n",
        "\n",
        "    return results_combined\n"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1743040070695
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 1. Load data\n",
        "user_df, product_df = process_data_sample(\n",
        "    dataset_str=\"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "    review_key=\"raw_review_Amazon_Fashion\",\n",
        "    meta_key=\"raw_meta_Amazon_Fashion\",\n",
        "    sampling_percent=5\n",
        ")\n",
        "print(user_df.shape)\n",
        "\n",
        "# user_df = user_df.head(100)\n",
        "\n",
        "# Extract all unique item_ids from the user_df\n",
        "item_ids = user_df['item_id'].unique()\n",
        "\n",
        "# Filter product_df to keep only those items that appear in user_df\n",
        "product_df = product_df[product_df['item_id'].isin(item_ids)].reset_index(drop=True)\n",
        "print(product_df.shape)\n",
        "\n",
        "# 4. Prepare training pairs\n",
        "train_df, test_df, train_pairs, test_pairs = prepare_pairwise_ranking_data_with_user_split(user_df, product_df)\n",
        "\n",
        "# Run full multimodal setup\n",
        "results_mm = run_ablation_experiment(ablation=False)\n",
        "\n",
        "# Run ablation with text-only embeddings\n",
        "results_text = run_ablation_experiment(ablation=True)\n",
        "\n",
        "# Combine the two results under separate keys\n",
        "combined_results = {\n",
        "    \"Multimodal Embeddings\": results_mm,\n",
        "    \"Text-only Embeddings\": results_text\n",
        "}\n",
        "\n",
        "# Save to a combined JSON file\n",
        "with open(\"ablation_results_combined.json\", \"w\") as f:\n",
        "    json.dump(combined_results, f, indent=2)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(125047, 10)\n(93236, 5)\n❌ Failed to load image from https://m.media-amazon.com/images/I/51KhClp4jKL._AC_.jpg — HTTPSConnectionPool(host='m.media-amazon.com', port=443): Read timed out. (read timeout=5)\n❌ Failed to load image from https://m.media-amazon.com/images/I/41xl5GXTHkL._AC_.jpg — HTTPSConnectionPool(host='m.media-amazon.com', port=443): Read timed out. (read timeout=5)\n❌ Failed to load image from https://m.media-amazon.com/images/I/317sbhEtEZL._AC_.jpg — cannot identify image file <_io.BytesIO object at 0x7f9bc18d04f0>\n❌ Failed to load image from https://m.media-amazon.com/images/I/51nfuaDfBwL._AC_.jpg — HTTPSConnectionPool(host='m.media-amazon.com', port=443): Read timed out. (read timeout=5)\n❌ Failed to load image from https://m.media-amazon.com/images/I/41p3AOz0j8L._AC_.jpg — HTTPSConnectionPool(host='m.media-amazon.com', port=443): Read timed out. (read timeout=5)\n❌ Failed to load image from https://m.media-amazon.com/images/I/41EHq1K13bL._AC_.jpg — HTTPSConnectionPool(host='m.media-amazon.com', port=443): Read timed out. (read timeout=5)\n❌ Failed to load image from https://m.media-amazon.com/images/I/513KYDXMbhL._AC_.jpg — HTTPSConnectionPool(host='m.media-amazon.com', port=443): Read timed out. (read timeout=5)\n❌ Failed to load image from https://m.media-amazon.com/images/I/41JChFK465L._AC_.jpg — HTTPSConnectionPool(host='m.media-amazon.com', port=443): Read timed out. (read timeout=5)\nEpoch 5, Loss: 0.2157\n========== Ablation: False ==========\nTrain pairs: 5103\nTest pairs: 999\nMLP Model Test Accuracy: 0.55\nDot Product Model Test Accuracy: 0.50\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " 87%|████████▋ | 4433/5103 [00:18<00:02, 243.04it/s]"
        }
      ],
      "execution_count": 83,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}